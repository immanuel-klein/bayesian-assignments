---
title: "Assignment 3"
format: pdf
author:
  - name: "Kerem Karag√∂z"
  - name: "Immanuel Klein"
editor: visual
execute: 
  warning: false
---

# General Information

-   **Points**: Assignment 3 comprises of 6 tasks, 2 points each (12 in total). 2 points are obtained for complete and correct answers. 1 point is obtained for a proper approach or if only part of the task is solved.

-   **Submission**: Hand in the assignment as a `Markdown` report ([RMarkdown](https://rmarkdown.rstudio.com/lesson-15.html) or [Quarto](https://rstudio.github.io/cheatsheets/html/quarto.html)) rendered as PDF. The PDF report should show the result(s), the code that produced the result(s), and possibly additional text or comment. Also indicate your name. The report should be uploaded on Moodle until Wednesday, June 21, 9:45 am.

-   **Working in teams**: Everyone needs to hand in a report on Moodle. However, the report can be handed in as a team work (max. 2 people). When working in teams, state at the beginning of the document, who you worked with. It Ideally, teams use GitHub and add a link to the GitHub repository to which both contributed.

-   **Code**: To automate code wrapping (such that long code lines are not cut off), install the [formatR](https://bookdown.org/yihui/rmarkdown-cookbook/opts-tidy.html) package and add the following code chunk at the beginning of the document:

```{r}
knitr::opts_chunk$set(tidy = TRUE, tidy.opts=list(width.cutoff=50))
```

\newpage

Load the data set `shaq` to solve the tasks below. If the `Markdown` document and the data set are stored in different folders (e.g., "BayesIntro/assignments/assignment_3.md" and "BayesIntro/data/shaq.csv" you can use the [package `here`](https://cran.r-project.org/web/packages/here/vignettes/rmarkdown.html) to load the data.

```{r}
#load packages here
library(dplyr)
library(ggplot2)
library(tinytex)
library(rethinking)
```

```{r}
#load data here
shaq <- read.csv("shaq.csv")
```

# Task Set 1

For Tasks 1.1 and 1.2, create a training data set `shaq_training` that contains all the data from the `Season` 1 to 5.

```{r}
shaq.first.seasons <- shaq %>% filter(Season >= 1 & Season <= 5)
head(shaq.first.seasons)
```

## Task 1.1

Use the training data and estimate a simple regression model where you predict points (PTS) from field goal attempts (FGA). Specify the regression model such that the intercept represents the expected number of points, given an average number of FGA. Provide a table that summarizes the posterior distribution.

```{r}
model1 <- quap(
  alist(
    PTS ~ dnorm(mu, sd), 
    mu <- a + b * (FGA - mean(FGA)), 
    # Because I have basically no knowledge of basketball metrics,
    # I choose the priors based on examples from the lecture code 
    # and after some trial error with the quap function
    a ~ dnorm(20, 8),
    b ~ dunif(0, 3),
    sd ~ dunif(0, 8)
  ),
  data = shaq.first.seasons)

summary(model1)
```

## Task 1.2

Estimate a multiple regression model, where you add free throw attempts (FTA) as a second predictor. Again, the intercept should represents the expected number of points, given an average number of FGA and FTA. Provide a table that summarizes the posterior distribution.

```{r}
model2 <- quap(
  alist(
    PTS ~ dnorm(mu, sd), 
    mu <- a + b1 * (FGA - mean(FGA)) + b2 * (FTA - mean(FTA)), 
    # Again: Because I have basically no knowledge of basketball metrics,
    # I choose the priors based on examples from the lecture code 
    # and after some trial error with the quap function
    a ~ dnorm(20, 8),
    b1 ~ dunif(0, 3),
    b2 ~ dunif(0, 3),
    sd ~ dunif(0, 8)
  ),
  data = shaq.first.seasons)

summary(model2)
```

\newpage

# Task Set 2

For Tasks 2.1 and 2.2, create a training data set `shaq_test` that contains all the data from the `Season` 6 to 10.

```{r}
shaq_test <- shaq %>% filter(Season >= 6 & Season <= 10)
head(shaq_test)
```

# Task 2.1

Use posterior samples from the simple regression model that you estimated in Task 1.1 and the FGA data from the test set to predict new points. Create a plot that shows the predicted point distribution along the actual point distribution from Season `Season` 6 to 10.

```{r}
# Extracting posterior samples
post.model1 <- extract.samples(model1)

# Replicating the mean values to match the dimensions
mean.FGA <- mean(shaq$FGA)
FGA.adj <- shaq_test$FGA - mean.FGA

# Making predictions
PTS.predicted <- post.model1$a + post.model1$a + post.model1$b %*% t(FGA.adj)

# Summarizing predictions
pred.summary <- apply(PTS.predicted, 2, mean)
actual.pts <- shaq_test$PTS

# Plotting predictions vs actual
plot.df1 <- data.frame(
  Season = shaq_test$Season,
  Actual = actual.pts,
  Predicted = pred.summary
)

ggplot(plot.df1, aes(x = Season)) +
  geom_line(aes(y = Actual, color = 'Actual')) +
  geom_line(aes(y = Predicted, color = 'Predicted')) +
  labs(title = 'Predicted vs Actual Points (Simple Regression)',
       y = 'Points', color = 'Legend')
```

# Task 2.2

Use posterior samples from the multiple regression model that you estimated in Task 1.2 and the FGA and FTA data from the test set to predict new points. Create a plot that shows the predicted point distribution along the actual point distribution from Season `Season` 6 to 10.

```{r}
# Extracting posterior samples
post.model2 <- extract.samples(model2)

# Replicating the mean values to match the dimensions for FTA as well
mean.FTA <- mean(shaq$FTA)
FTA.adj <- shaq_test$FTA - mean.FTA

# Making predictions
PTS.predicted.multi <- post.model2$a + post.model2$b1 %*% t(FGA.adj) + 
post.model2$b2 %*% t(FTA.adj)

# Summarizing predictions
pred.summary.multi <- apply(PTS.predicted.multi, 2, mean)
actual.pts.multi <- shaq_test$PTS

# Plotting predictions vs actual
plot.df2 <- data.frame(
  Season = shaq_test$Season,
  Actual = actual.pts.multi,
  Predicted = pred.summary.multi
)

ggplot(plot.df2, aes(x = Season)) +
  geom_line(aes(y = Actual, color = 'Actual')) +
  geom_line(aes(y = Predicted, color = 'Predicted')) +
  labs(title = 'Predicted vs Actual Points (Multiple Regression)',
       y = 'Points', color = 'Legend')
```

\newpage

# Task Set 3

## Task 3.1

Write a function `error()` that takes the predicted points $\hat{y}$ and the observed points $y$ to compute the sum of squared errors:

$$
\sum_i^n(\hat{y}_i - y_i)^2
$$ Compute the squared errors for the simple regression model and the multiple regression model. Which model makes better predictions for the test data?

```{r}
# Function to compute sum of squared errors
error <- function(actual, predicted) {
  sum((actual - predicted)^2)
}

# Calculate SSE for both models
sse <- sapply(list(
  simple = list(actual = actual.pts, predicted = pred.summary),
  multiple = list(actual = actual.pts.multi, predicted = pred.summary.multi)
), function(x) error(x$actual, x$predicted))

sse

# Determine the better model
better.model <- ifelse(sse["simple"] < sse["multiple"], 
                       "Simple Regression", "Multiple Regression")

cat("Sum of Squared Errors (SSE):\n",
    "Simple Regression: ", sse["simple"], "\n",
    "Multiple Regression: ", sse["multiple"], "\n",
    "Better Model: ", better.model, "\n")
```

## Task 3.2

For both models, compute the (non-squared) differences between each prediction and observation. Create a plot that shows the distributions of differences for both models.

```{r}
# Calculate differences for both models
differences <- data.frame(
  Model = rep(c("Simple Regression", "Multiple Regression"), each = 
  length(actual.pts)),
  Differences = c(actual.pts - pred.summary, 
  actual.pts.multi - pred.summary.multi)
)

# Plot distributions of differences
ggplot(differences, aes(x = Differences, fill = Model)) +
  geom_histogram(alpha = 0.6, position = "identity", bins = 30) +
  labs(title = "Distribution of Prediction Errors",
       x = "Prediction Error", fill = "Model")
```
